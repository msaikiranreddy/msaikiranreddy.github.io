<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- Primary Meta Tags -->
    <title>Architecting Real-Time Data Platforms at Multi-Billion Row Scale | Sai Kiran Malikireddy</title>
    <meta name="title" content="Architecting Real-Time Data Platforms at Multi-Billion Row Scale">
    <meta name="description" content="Deep dive into architectural patterns, technology choices, and optimization strategies for building ultra-high-throughput real-time data processing systems. Learn from production experience at Walmart scale.">
    <meta name="keywords" content="real-time data processing, distributed systems, data architecture, Apache Kafka, stream processing, big data, scalability, Sai Kiran Malikireddy">
    <meta name="author" content="Sai Kiran Malikireddy">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://msaikiranreddy.github.io/blog/multibillion-realtime-data-platforms">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://msaikiranreddy.github.io/blog/multibillion-realtime-data-platforms">
    <meta property="og:title" content="Architecting Real-Time Data Platforms at Multi-Billion Row Scale">
    <meta property="og:description" content="Deep dive into architectural patterns for building ultra-high-throughput real-time data processing systems at enterprise scale.">
    <meta property="og:image" content="https://msaikiranreddy.github.io/images/realtime-data-og.jpg">
    <meta property="og:site_name" content="Sai Kiran Malikireddy">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://msaikiranreddy.github.io/blog/multibillion-realtime-data-platforms">
    <meta property="twitter:title" content="Architecting Real-Time Data Platforms at Multi-Billion Row Scale">
    <meta property="twitter:description" content="Deep dive into architectural patterns for building ultra-high-throughput real-time data processing systems.">
    <meta property="twitter:image" content="https://msaikiranreddy.github.io/images/realtime-data-twitter.jpg">
    
    <!-- Schema.org Article Markup -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "BlogPosting",
      "headline": "Architecting Real-Time Data Platforms at Multi-Billion Row Scale",
      "description": "Deep dive into architectural patterns, technology choices, and optimization strategies for building ultra-high-throughput real-time data processing systems.",
      "image": "https://msaikiranreddy.github.io/images/realtime-data.jpg",
      "author": {
        "@type": "Person",
        "name": "Sai Kiran Malikireddy",
        "url": "https://www.linkedin.com/in/saikiranmalikireddy/",
        "jobTitle": "Distinguished Engineer",
        "worksFor": {
          "@type": "Organization",
          "name": "Walmart Global Tech"
        }
      },
      "publisher": {
        "@type": "Person",
        "name": "Sai Kiran Malikireddy"
      },
      "datePublished": "2024-12-20",
      "dateModified": "2024-12-20",
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://msaikiranreddy.github.io/blog/realtime-data-platforms-scale"
      },
      "keywords": ["real-time data processing", "distributed systems", "data architecture", "Apache Kafka", "stream processing"],
      "articleSection": "Technology",
      "wordCount": 2500,
      "timeRequired": "PT12M"
    }
    </script>
    <script>
  document.addEventListener('contextmenu', function(event) {
    event.preventDefault();
  });
</script>
    
    <!-- Schema.org Breadcrumb -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "BreadcrumbList",
      "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "name": "Home",
        "item": "https://msaikiranreddy.github.io/"
      },{
        "@type": "ListItem",
        "position": 2,
        "name": "Blog",
        "item": "https://msaikiranreddy.github.io/#blog"
      },{
        "@type": "ListItem",
        "position": 3,
        "name": "Real-Time Data Platforms at Scale"
      }]
    }
    </script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --primary: #0f172a;
            --secondary: #1e293b;
            --accent: #3b82f6;
            --accent-hover: #2563eb;
            --text: #f1f5f9;
            --text-dim: #cbd5e1;
            --text-muted: #94a3b8;
            --card-bg: #1e293b;
            --border: #334155;
            --code-bg: #0d1117;
        }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.8;
            color: var(--text);
            background: var(--primary);
        }
        
        header {
            background: rgba(30, 41, 59, 0.95);
            backdrop-filter: blur(12px);
            border-bottom: 1px solid var(--border);
            padding: 1.2rem 0;
            position: sticky;
            top: 0;
            z-index: 1000;
        }
        
        nav {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .logo {
            font-size: 1.5rem;
            font-weight: 700;
            background: linear-gradient(135deg, var(--accent) 0%, #60a5fa 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-decoration: none;
        }
        
        nav a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.3s;
        }
        
        nav a:hover {
            color: var(--accent);
        }
        
        .breadcrumb {
            max-width: 800px;
            margin: 2rem auto 0;
            padding: 0 2rem;
            font-size: 0.9rem;
            color: var(--text-muted);
        }
        
        .breadcrumb a {
            color: var(--accent);
            text-decoration: none;
        }
        
        .breadcrumb a:hover {
            text-decoration: underline;
        }
        
        article {
            max-width: 800px;
            margin: 3rem auto;
            padding: 0 2rem;
        }
        
        .article-header {
            margin-bottom: 3rem;
        }
        
        .article-meta {
            display: flex;
            gap: 1.5rem;
            font-size: 0.9rem;
            color: var(--text-muted);
            margin-bottom: 1.5rem;
            flex-wrap: wrap;
        }
        
        .tag {
            display: inline-block;
            padding: 0.4rem 1rem;
            background: rgba(59, 130, 246, 0.2);
            color: var(--accent);
            border-radius: 6px;
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        h1 {
            font-size: 2.8rem;
            line-height: 1.2;
            margin-bottom: 1.5rem;
            color: var(--text);
            font-weight: 800;
        }
        
        .article-intro {
            font-size: 1.25rem;
            color: var(--text-dim);
            line-height: 1.7;
            margin-bottom: 2rem;
            padding-left: 1rem;
            border-left: 4px solid var(--accent);
        }
        
        .author-info {
            display: flex;
            align-items: center;
            gap: 1rem;
            padding: 1.5rem;
            background: var(--card-bg);
            border-radius: 12px;
            margin-bottom: 3rem;
        }
        
        .author-avatar {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--accent) 0%, #60a5fa 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5rem;
            color: white;
            font-weight: bold;
        }
        
        .author-details h3 {
            font-size: 1.1rem;
            margin-bottom: 0.3rem;
            color: var(--text);
        }
        
        .author-details p {
            font-size: 0.9rem;
            color: var(--text-muted);
        }
        
        .article-content h2 {
            font-size: 2rem;
            margin: 3rem 0 1.5rem;
            color: var(--text);
            font-weight: 700;
        }
        
        .article-content h3 {
            font-size: 1.5rem;
            margin: 2.5rem 0 1rem;
            color: var(--text);
            font-weight: 600;
        }
        
        .article-content p {
            margin-bottom: 1.5rem;
            font-size: 1.1rem;
            color: var(--text-dim);
        }
        
        .article-content ul, .article-content ol {
            margin: 1.5rem 0;
            padding-left: 2rem;
            color: var(--text-dim);
        }
        
        .article-content li {
            margin-bottom: 0.8rem;
            font-size: 1.1rem;
        }
        
        .article-content strong {
            color: var(--text);
            font-weight: 600;
        }
        
        .highlight-box {
            background: var(--card-bg);
            border-left: 4px solid var(--accent);
            padding: 1.5rem;
            margin: 2rem 0;
            border-radius: 8px;
        }
        
        .highlight-box h4 {
            color: var(--accent);
            margin-bottom: 1rem;
            font-size: 1.2rem;
        }
        
        code {
            background: var(--code-bg);
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.95rem;
            color: #60a5fa;
        }
        
        pre {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 2rem 0;
            border: 1px solid var(--border);
        }
        
        pre code {
            background: none;
            padding: 0;
            font-size: 0.9rem;
            color: var(--text-dim);
            line-height: 1.6;
        }
        
        .key-takeaways {
            background: linear-gradient(135deg, rgba(59, 130, 246, 0.1) 0%, rgba(16, 185, 129, 0.1) 100%);
            border: 1px solid var(--accent);
            padding: 2rem;
            border-radius: 12px;
            margin: 3rem 0;
        }
        
        .key-takeaways h3 {
            color: var(--accent);
            margin-bottom: 1rem;
        }
        
        .share-section {
            margin: 4rem 0;
            padding: 2rem;
            background: var(--card-bg);
            border-radius: 12px;
            text-align: center;
        }
        
        .share-section h3 {
            margin-bottom: 1.5rem;
            color: var(--text);
        }
        
        .share-buttons {
            display: flex;
            gap: 1rem;
            justify-content: center;
            flex-wrap: wrap;
        }
        
        .share-btn {
            padding: 0.8rem 1.5rem;
            background: var(--accent);
            color: white;
            text-decoration: none;
            border-radius: 8px;
            transition: all 0.3s;
            font-weight: 600;
        }
        
        .share-btn:hover {
            background: var(--accent-hover);
            transform: translateY(-2px);
        }
        
        .related-articles {
            margin: 4rem 0;
        }
        
        .related-articles h3 {
            margin-bottom: 2rem;
            color: var(--text);
            font-size: 2rem;
        }
        
        .related-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 2rem;
        }
        
        .related-card {
            background: var(--card-bg);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 1.5rem;
            text-decoration: none;
            color: var(--text);
            transition: all 0.3s;
        }
        
        .related-card:hover {
            border-color: var(--accent);
            transform: translateY(-5px);
        }
        
        .related-card h4 {
            margin-bottom: 0.5rem;
            color: var(--text);
        }
        
        .related-card p {
            font-size: 0.9rem;
            color: var(--text-muted);
        }
        
        footer {
            background: var(--card-bg);
            border-top: 1px solid var(--border);
            padding: 2rem 0;
            text-align: center;
            color: var(--text-muted);
            margin-top: 5rem;
        }
        
        @media (max-width: 768px) {
            h1 {
                font-size: 2rem;
            }
            
            .article-content h2 {
                font-size: 1.6rem;
            }
            
            .article-content h3 {
                font-size: 1.3rem;
            }
            
            article {
                padding: 0 1.5rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <nav>
            <a href="/" class="logo">SKM</a>
            <a href="/">‚Üê Back to Home</a>
        </nav>
    </header>
    
    <div class="breadcrumb">
        <a href="/">Home</a> / <a href="/blog">Blog</a> / Real-Time Data Platforms at Scale
    </div>
    
    <article>
        <div class="article-header">
            <div class="article-meta">
                <span class="tag">Architecture</span>
                <span>üìÖ December 20, 2024</span>
                <span>‚è±Ô∏è 12 min read</span>
                
            </div>
            
            <h1>Architecting Real-Time Data Platforms at Multi-Billion Row Scale</h1>
            
            <p class="article-intro">
                Building data platforms that process billions of rows in real-time isn't just about choosing the right technologies‚Äîit's about understanding distributed systems fundamentals, making informed architectural tradeoffs, and designing for inevitable failure scenarios.
            </p>
            
            <div class="author-info">
                <div class="author-avatar">SK</div>
                <div class="author-details">
                    <h3>Sai Kiran Malikireddy</h3>
                    <p>Distinguished Engineer @ Walmart Global Tech | 10+ years in distributed systems</p>
                </div>
            </div>
        </div>
        
        <div class="article-content">
            <h2>The Real-Time Data Challenge</h2>
            
            <p>
                In today's digital economy, the ability to process and act on data in real-time has become a critical competitive advantage. Whether it's powering recommendation engines, detecting fraud, optimizing supply chains, or personalizing customer experiences, organizations need to handle massive data volumes with millisecond latencies.
            </p>
            
            <p>
                At Walmart, we've built real-time data platforms that process billions of events daily, supporting everything from inventory management to customer analytics. Here's what we've learned from architecting these systems at scale.
            </p>
            
            <h2>Core Architectural Principles</h2>
            
            <h3>1. Design for Horizontal Scalability from Day One</h3>
            
            <p>
                The most critical decision in building scalable data platforms is ensuring every component can scale horizontally. This means:
            </p>
            
            <ul>
                <li><strong>Stateless processing layers</strong> that can be replicated without coordination</li>
                <li><strong>Partitioned data stores</strong> that distribute load across multiple nodes</li>
                <li><strong>Sharded message queues</strong> that parallelize data ingestion</li>
                <li><strong>Load-balanced API gateways</strong> that handle traffic spikes gracefully</li>
            </ul>
            
            <p>
                We learned this lesson the hard way. Our initial architecture had stateful components that became bottlenecks at scale. Redesigning for horizontal scalability allowed us to grow from processing millions to billions of records daily.
            </p>
            
            <div class="highlight-box">
                <h4>üí° Pro Tip: The Scalability Test</h4>
                <p>
                    Ask yourself: "If traffic doubles overnight, can I handle it by adding more machines?" If the answer involves code changes or architectural redesign, you have a scalability problem.
                </p>
            </div>
            
            <h3>2. Embrace Event-Driven Architecture</h3>
            
            <p>
                Event-driven architectures are the backbone of real-time systems. They provide:
            </p>
            
            <ul>
                <li><strong>Decoupling:</strong> Producers and consumers operate independently</li>
                <li><strong>Scalability:</strong> Each component scales based on its own load</li>
                <li><strong>Resilience:</strong> Failures in one component don't cascade</li>
                <li><strong>Flexibility:</strong> New consumers can be added without affecting producers</li>
            </ul>
            
            <p>
                Apache Kafka has been our workhorse for event streaming, but the principles apply to any message broker. The key is treating events as first-class citizens in your architecture.
            </p>
            
            <pre><code>// Event Schema Example
{
  "eventId": "uuid-v4",
  "eventType": "user.action.checkout",
  "timestamp": "2024-12-20T10:30:00Z",
  "userId": "user-12345",
  "payload": {
    "cartValue": 149.99,
    "items": [...],
    "location": "store-5678"
  },
  "metadata": {
    "source": "mobile-app",
    "version": "2.5.1"
  }
}</code></pre>
            
            <h3>3. Optimize for the 99th Percentile, Not the Average</h3>
            
            <p>
                Average latency metrics are misleading. What matters is tail latency‚Äîthe experience of your slowest users. In distributed systems, tail latencies compound:
            </p>
            
            <ul>
                <li>If you call 10 services each with p99 latency of 100ms, your p99 becomes ~1 second</li>
                <li>Slow requests consume resources longer, creating a cascading effect</li>
                <li>The worst user experiences often correlate with the most valuable customers (complex accounts, large transactions)</li>
            </ul>
            
            <p>
                We obsessively monitor p95, p99, and p99.9 latencies, and optimize specifically for these percentiles through techniques like:
            </p>
            
            <ul>
                <li>Strategic caching at multiple layers</li>
                <li>Request hedging and speculative execution</li>
                <li>Circuit breakers and graceful degradation</li>
                <li>Optimized data structures and algorithms for hot paths</li>
            </ul>
            
            <h2>Technology Stack Deep Dive</h2>
            
            <h3>Data Ingestion Layer</h3>
            
            <p>
                The ingestion layer is where data enters your platform. It must be:
            </p>
            
            <ul>
                <li><strong>Highly available:</strong> No single point of failure</li>
                <li><strong>Durable:</strong> No data loss, even during failures</li>
                <li><strong>Backpressure-aware:</strong> Handle traffic spikes without dropping data</li>
            </ul>
            
            <p>
                Our stack leverages Apache Kafka for ingestion, configured with:
            </p>
            
            <ul>
                <li>Replication factor of 3 for durability</li>
                <li>min.insync.replicas of 2 for consistency</li>
                <li>Compression (snappy) for bandwidth optimization</li>
                <li>Partitioning strategy aligned with processing needs</li>
            </ul>
            
            <h3>Stream Processing Layer</h3>
            
            <p>
                Real-time transformations, aggregations, and enrichment happen here. We use Apache Flink for stateful stream processing because it provides:
            </p>
            
            <ul>
                <li><strong>Exactly-once semantics:</strong> Critical for financial transactions</li>
                <li><strong>Event time processing:</strong> Handles out-of-order events correctly</li>
                <li><strong>State management:</strong> Efficient checkpointing and recovery</li>
                <li><strong>Windowing operations:</strong> Time-based aggregations at scale</li>
            </ul>
            
            <div class="key-takeaways">
                <h3>üéØ Key Architectural Decisions</h3>
                <ul>
                    <li>Choose horizontal scalability over vertical from day one</li>
                    <li>Implement event-driven patterns for decoupling and resilience</li>
                    <li>Optimize for tail latencies (p99), not averages</li>
                    <li>Design for failure‚Äîit's not if systems fail, but when</li>
                    <li>Monitor everything, but alert on what matters</li>
                </ul>
            </div>
            
            <h3>Storage Layer Considerations</h3>
            
            <p>
                Storage is where many real-time systems hit walls. Key considerations:
            </p>
            
            <ul>
                <li><strong>Cassandra for write-heavy workloads:</strong> Linear scalability, tunable consistency</li>
                <li><strong>Redis for hot data caching:</strong> Sub-millisecond reads, pub/sub capabilities</li>
                <li><strong>S3 for cold storage:</strong> Infinite scalability, cost-effective archival</li>
                <li><strong>Elasticsearch for full-text search:</strong> Real-time indexing, complex queries</li>
            </ul>
            
            <p>
                The key is using the right tool for each access pattern. Polyglot persistence isn't complexity for its own sake‚Äîit's optimization for real-world requirements.
            </p>
            
            <h2>Operational Excellence</h2>
            
            <h3>Observability: The Three Pillars</h3>
            
            <p>
                You can't operate what you can't observe. Our observability strategy focuses on:
            </p>
            
            <ul>
                <li><strong>Metrics:</strong> Time-series data on throughput, latency, errors (Prometheus + Grafana)</li>
                <li><strong>Logs:</strong> Structured logging for debugging and audit trails (ELK stack)</li>
                <li><strong>Traces:</strong> End-to-end request tracking for latency analysis (Jaeger)</li>
            </ul>
            
            <p>
                The power comes from correlating these three. When latency spikes, you need to quickly trace the issue to specific components, view relevant logs, and understand the broader system metrics.
            </p>
            
            <h3>Chaos Engineering in Production</h3>
            
            <p>
                We regularly inject failures into production systems to validate resilience:
            </p>
            
            <ul>
                <li>Random pod terminations</li>
                <li>Network latency injection</li>
                <li>Resource exhaustion scenarios</li>
                <li>Dependency failure simulation</li>
            </ul>
            
            <p>
                This isn't recklessness‚Äîit's controlled testing that reveals weaknesses before they cause real outages. Every chaos experiment teaches us something about our system's resilience.
            </p>
            
            <h2>Performance Optimization Strategies</h2>
            
            <h3>1. Batch Where Possible, Stream Where Necessary</h3>
            
            <p>
                Not everything needs real-time processing. We use the Lambda Architecture pattern:
            </p>
            
            <ul>
                <li><strong>Speed layer:</strong> Real-time processing for immediate needs</li>
                <li><strong>Batch layer:</strong> Accurate, complete processing for historical data</li>
                <li><strong>Serving layer:</strong> Merges results from both layers</li>
            </ul>
            
            <p>
                This hybrid approach balances cost, latency, and accuracy requirements.
            </p>
            
            <h3>2. Smart Data Partitioning</h3>
            
            <p>
                Partitioning strategy directly impacts performance:
            </p>
            
            <ul>
                <li><strong>Hash partitioning:</strong> Even distribution, good for general workloads</li>
                <li><strong>Range partitioning:</strong> Efficient time-series queries, risk of hot spots</li>
                <li><strong>Composite partitioning:</strong> Combines strategies for complex access patterns</li>
            </ul>
            
            <p>
                We partition by customer ID for user-specific queries and by timestamp for analytics workloads, creating separate data flows optimized for each use case.
            </p>
            
            <h3>3. Caching Strategy: Multi-Level Defense</h3>
            
            <p>
                Our caching strategy operates at multiple levels:
            </p>
            
            <ul>
                <li><strong>CDN layer:</strong> Static content and API responses (CloudFront)</li>
                <li><strong>Application cache:</strong> Hot data in-memory (Redis)</li>
                <li><strong>Database cache:</strong> Query results and computed values</li>
                <li><strong>Client-side cache:</strong> Browser/app caching for offline capability</li>
            </ul>
            
            <p>
                Each layer has different TTLs and invalidation strategies based on data freshness requirements and update patterns.
            </p>
            
            <h2>Lessons from Production</h2>
            
            <h3>What Worked</h3>
            
            <ul>
                <li>Starting with distributed systems principles, not just technologies</li>
                <li>Investing heavily in observability before scaling</li>
                <li>Building auto-scaling from the ground up</li>
                <li>Creating clear service boundaries and contracts</li>
                <li>Prioritizing developer experience and tooling</li>
            </ul>
            
            <h3>What We'd Do Differently</h3>
            
            <ul>
                <li>Implement chaos engineering earlier in the development cycle</li>
                <li>Standardize on fewer technologies initially (we had too much diversity)</li>
                <li>Build cost monitoring into the platform from day one</li>
                <li>Invest more in data quality validation at ingestion</li>
                <li>Create better data lineage tracking from the start</li>
            </ul>
            
            <h2>The Road Ahead: Emerging Trends</h2>
            
            <p>
                The real-time data landscape continues to evolve:
            </p>
            
            <ul>
                <li><strong>Serverless stream processing:</strong> Lower operational overhead, pay-per-use pricing</li>
                <li><strong>ML-powered optimization:</strong> Automated tuning of system parameters</li>
                <li><strong>Edge computing integration:</strong> Processing closer to data sources</li>
                <li><strong>Unified batch and streaming:</strong> Technologies like Apache Beam simplifying architecture</li>
            </ul>
            
            <h2>Conclusion</h2>
            
            <p>
                Building real-time data platforms at scale is a journey, not a destination. Technologies will change, but the fundamental principles remain constant: design for horizontal scalability, embrace failure as inevitable, optimize for tail latencies, and make systems observable.
            </p>
            
            <p>
                Success comes from balancing technical excellence with pragmatic tradeoffs. Not every decision needs to be perfect‚Äîit needs to be good enough today while enabling evolution tomorrow.
            </p>
            
            <p>
                The platforms we build today will power the AI-driven, real-time experiences of tomorrow. By grounding our architecture in distributed systems fundamentals while remaining flexible to new technologies, we position ourselves to meet whatever challenges come next.
            </p>
        </div>
        
        <div class="share-section">
            <h3>Found this helpful? Share it!</h3>
            <div class="share-buttons">
                <a href="https://twitter.com/intent/tweet?text=Architecting Real-Time Data Platforms at Multi-Billion Row Scale&url=https://msaikiranreddy.github.io/blog/realtime-data-platforms-scale" target="_blank" class="share-btn">Share on Twitter</a>
                <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://msaikiranreddy.github.io/blog/realtime-data-platforms-scale" target="_blank" class="share-btn">Share on LinkedIn</a>
            </div>
        </div>
        
        <div class="related-articles">
            <h3>Related Articles</h3>
            <div class="related-grid">
                 <footer>
        <div class="container">
            <p>&copy; 2025 Sai Kiran Malikireddy. All rights reserved.</p>
            <p style="margin-top: 0.5rem; font-size: 0.9rem;">Distinguished Engineer | Cloud Architect | AI/ML Specialist</p>
        </div>
    </footer>
                